{"cells":[{"source":"![clothing_classification](clothing_classification.png)\n","metadata":{},"id":"aaa02648-9eae-45ba-893f-88440e8e4235","cell_type":"markdown"},{"source":"Fashion Forward is a new AI-based e-commerce clothing retailer.\nThey want to use image classification to automatically categorize new product listings, making it easier for customers to find what they're looking for. It will also assist in inventory management by quickly sorting items.\n\nAs a data scientist tasked with implementing a garment classifier, your primary objective is to develop a machine learning model capable of accurately categorizing images of clothing items into distinct garment types such as shirts, trousers, shoes, etc.","metadata":{},"id":"ad5a988c-1095-485a-a88c-002400a872be","cell_type":"markdown"},{"source":"# Run the cells below first","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1744510414584,"lastExecutedByKernel":"be042d0d-3a07-4ca3-bffe-4ce605d8101f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run the cells below first"},"id":"4a1ab317-f3e4-4e5f-93a7-9c27677c5ffb","cell_type":"code","execution_count":38,"outputs":[]},{"source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall","metadata":{"executionCancelledAt":null,"executionTime":6062,"lastExecutedAt":1747116513733,"lastExecutedByKernel":"49d3785a-e163-4a5a-a018-aec0a1dde060","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall"},"id":"ea8065b7-84fc-4376-afef-6db731dec4b3","cell_type":"code","execution_count":1,"outputs":[]},{"source":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","metadata":{"executionCancelledAt":null,"executionTime":2220,"lastExecutedAt":1747116729809,"lastExecutedByKernel":"49d3785a-e163-4a5a-a018-aec0a1dde060","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","outputsMetadata":{"0":{"height":83,"type":"stream"},"1":{"height":39,"type":"stream"},"2":{"height":127,"type":"stream"},"3":{"height":39,"type":"stream"},"4":{"height":127,"type":"stream"},"5":{"height":39,"type":"stream"},"6":{"height":127,"type":"stream"},"7":{"height":39,"type":"stream"},"8":{"height":61,"type":"stream"}}},"id":"662e1bf1-943f-4243-9fd4-02ce11609e8d","cell_type":"code","execution_count":2,"outputs":[]},{"source":"# Get the number of classes\nclasses = train_data.classes\nnum_classes = len(train_data.classes) \nprint(num_classes)","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1747116750260,"lastExecutedByKernel":"49d3785a-e163-4a5a-a018-aec0a1dde060","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Get the number of classes\nclasses = train_data.classes\nnum_classes = len(train_data.classes) \nprint(num_classes)"},"cell_type":"code","id":"4ef2138b-72ce-448e-9c67-d519eedff080","outputs":[{"output_type":"stream","name":"stdout","text":"10\n"}],"execution_count":4},{"source":"# Define some relevant variables\nnum_input_channels = 1\nnum_output_channels = 16\nimage_size = train_data[0][0].shape[1]","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1747119912268,"lastExecutedByKernel":"49d3785a-e163-4a5a-a018-aec0a1dde060","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define some relevant variables\nnum_input_channels = 1\nnum_output_channels = 16\nimage_size = train_data[0][0].shape[1]"},"cell_type":"code","id":"f4092595-cf5e-441c-989e-3940f82a73b1","outputs":[],"execution_count":5},{"source":"# Define CNN\nclass MultiClassImageClassifier(nn.Module):\n  \n    # Define the init method\n    def __init__(self, num_classes):\n        super(MultiClassImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.flatten = nn.Flatten()\n\n        # Create a fully connected layer\n        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n        \n    def forward(self, x):\n        # Pass inputs through each layer\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.flatten(x)\n        x = self.fc(x)\n        return x","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1747119916444,"lastExecutedByKernel":"49d3785a-e163-4a5a-a018-aec0a1dde060","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define CNN\nclass MultiClassImageClassifier(nn.Module):\n  \n    # Define the init method\n    def __init__(self, num_classes):\n        super(MultiClassImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.flatten = nn.Flatten()\n\n        # Create a fully connected layer\n        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n        \n    def forward(self, x):\n        # Pass inputs through each layer\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.flatten(x)\n        x = self.fc(x)\n        return x"},"cell_type":"code","id":"e32a3561-a792-4461-8798-7fdc64759075","outputs":[],"execution_count":6},{"source":"# Define the training set DataLoader\ndataloader_train = DataLoader(\n    train_data,\n    batch_size=10,\n    shuffle=True,\n)","metadata":{"executionCancelledAt":null,"executionTime":8,"lastExecutedAt":1747119920744,"lastExecutedByKernel":"49d3785a-e163-4a5a-a018-aec0a1dde060","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the training set DataLoader\ndataloader_train = DataLoader(\n    train_data,\n    batch_size=10,\n    shuffle=True,\n)"},"cell_type":"code","id":"8c6c12b8-a46a-431c-bc30-80b3779e6d96","outputs":[],"execution_count":7},{"source":"# Define training function\ndef train_model(optimizer, net, num_epochs):\n    num_processed = 0\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(num_epochs):\n        running_loss = 0\n        num_processed = 0\n        for features, labels in dataloader_train:\n            optimizer.zero_grad()\n            outputs = net(features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            num_processed += len(labels)\n        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n        \n    train_loss = running_loss / len(dataloader_train)\n","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1747119922943,"lastExecutedByKernel":"49d3785a-e163-4a5a-a018-aec0a1dde060","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define training function\ndef train_model(optimizer, net, num_epochs):\n    num_processed = 0\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(num_epochs):\n        running_loss = 0\n        num_processed = 0\n        for features, labels in dataloader_train:\n            optimizer.zero_grad()\n            outputs = net(features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            num_processed += len(labels)\n        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n        \n    train_loss = running_loss / len(dataloader_train)\n"},"cell_type":"code","id":"2dc8db85-bbd9-419b-9352-e9ec3f9f5156","outputs":[],"execution_count":8},{"source":"# Train for 1 epoch\nnet = MultiClassImageClassifier(num_classes)\noptimizer = optim.Adam(net.parameters(), lr=0.001)\n\ntrain_model(\n    optimizer=optimizer,\n    net=net,\n    num_epochs=1,\n)","metadata":{"executionCancelledAt":null,"executionTime":15496,"lastExecutedAt":1747119941868,"lastExecutedByKernel":"49d3785a-e163-4a5a-a018-aec0a1dde060","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Train for 1 epoch\nnet = MultiClassImageClassifier(num_classes)\noptimizer = optim.Adam(net.parameters(), lr=0.001)\n\ntrain_model(\n    optimizer=optimizer,\n    net=net,\n    num_epochs=1,\n)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"bbfb5482-c965-4374-bdef-3b76a0378714","outputs":[{"output_type":"stream","name":"stdout","text":"epoch 0, loss: 0.040822478539380244\n"}],"execution_count":9},{"source":"# Test the model on the test set\n              \n# Define the test set DataLoader\ndataloader_test = DataLoader(\n    test_data,\n    batch_size=10,\n    shuffle=False,\n)","metadata":{"executionCancelledAt":null,"executionTime":9,"lastExecutedAt":1747119944654,"lastExecutedByKernel":"49d3785a-e163-4a5a-a018-aec0a1dde060","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Test the model on the test set\n              \n# Define the test set DataLoader\ndataloader_test = DataLoader(\n    test_data,\n    batch_size=10,\n    shuffle=False,\n)"},"cell_type":"code","id":"578adbeb-8c23-416a-abc1-0b46f31dae51","outputs":[],"execution_count":10},{"source":"# Define the metrics\naccuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\nprecision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)","metadata":{"executionCancelledAt":null,"executionTime":18,"lastExecutedAt":1747119952257,"lastExecutedByKernel":"49d3785a-e163-4a5a-a018-aec0a1dde060","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the metrics\naccuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\nprecision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)"},"cell_type":"code","id":"5d53ba27-6527-4085-8471-5159744e68d3","outputs":[],"execution_count":11},{"source":"# Run model on test set\nnet.eval()\npredictions = []\nfor i, (features, labels) in enumerate(dataloader_test):\n    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n    cat = torch.argmax(output, dim=-1)\n    predictions.extend(cat.tolist())\n    accuracy_metric(cat, labels)\n    precision_metric(cat, labels)\n    recall_metric(cat, labels)","metadata":{"executionCancelledAt":null,"executionTime":2581,"lastExecutedAt":1747119957780,"lastExecutedByKernel":"49d3785a-e163-4a5a-a018-aec0a1dde060","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run model on test set\nnet.eval()\npredictions = []\nfor i, (features, labels) in enumerate(dataloader_test):\n    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n    cat = torch.argmax(output, dim=-1)\n    predictions.extend(cat.tolist())\n    accuracy_metric(cat, labels)\n    precision_metric(cat, labels)\n    recall_metric(cat, labels)"},"cell_type":"code","id":"1cafae32-ef22-44c5-a988-1c10aedc8d88","outputs":[],"execution_count":12},{"source":"# Compute the metrics\naccuracy = accuracy_metric.compute().item()\nprecision = precision_metric.compute().tolist()\nrecall = recall_metric.compute().tolist()\nprint('Accuracy:', accuracy)\nprint('Precision (per class):', precision)\nprint('Recall (per class):', recall)","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1747119961413,"lastExecutedByKernel":"49d3785a-e163-4a5a-a018-aec0a1dde060","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Compute the metrics\naccuracy = accuracy_metric.compute().item()\nprecision = precision_metric.compute().tolist()\nrecall = recall_metric.compute().tolist()\nprint('Accuracy:', accuracy)\nprint('Precision (per class):', precision)\nprint('Recall (per class):', recall)","outputsMetadata":{"0":{"height":122,"type":"stream"}}},"cell_type":"code","id":"fc16ec84-6396-41e4-8169-4ac6c0704450","outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy: 0.882099986076355\nPrecision (per class): [0.7806167602539062, 0.9645669460296631, 0.7704626321792603, 0.9265850782394409, 0.8064823746681213, 0.99148029088974, 0.7694370150566101, 0.9110487103462219, 0.9467570185661316, 0.9626639485359192]\nRecall (per class): [0.8859999775886536, 0.9800000190734863, 0.8659999966621399, 0.8330000042915344, 0.8460000157356262, 0.9309999942779541, 0.5740000009536743, 0.9729999899864197, 0.9779999852180481, 0.9539999961853027]\n"}],"execution_count":13}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}